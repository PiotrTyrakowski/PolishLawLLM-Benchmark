{
 "cells": [
  {
   "metadata": {
    "id": "a7137b7b16ff965e"
   },
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PiotrTyrakowski/PolishLawLLM-Benchmark/blob/KwiatkowskiML/bielik-notebook/notebooks/bielik.ipynb)\n"
   ],
   "id": "a7137b7b16ff965e"
  },
  {
   "cell_type": "code",
   "source": [
    "from benchmark_framework.models.bielik import BielikModel\n",
    "\n",
    "rm -fr PolishLawLLM-Benchmark/"
   ],
   "metadata": {
    "id": "LgE1ZzTQPrw9"
   },
   "id": "LgE1ZzTQPrw9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone -b KwiatkowskiML/bielik-notebook https://github.com/PiotrTyrakowski/PolishLawLLM-Benchmark.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwRNKw_wLppv",
    "outputId": "8d56577e-941d-410e-cd31-8b21d48b14f9"
   },
   "id": "UwRNKw_wLppv",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%cd PolishLawLLM-Benchmark/\n",
    "!pip install -e ."
   ],
   "metadata": {
    "id": "ZvACMCXfP1mY",
    "outputId": "3344b821-63da-4b3b-9b1e-458702f425f1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "ZvACMCXfP1mY",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true,
    "id": "520fa617a1609128"
   },
   "cell_type": "code",
   "source": [
    "!pip install -q transformers torch accelerate sentencepiece"
   ],
   "id": "520fa617a1609128",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8d3d76e0798144f",
    "outputId": "07f9dca1-3216-44ee-a95a-2fc5ce300aab"
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using: {device}\")"
   ],
   "id": "b8d3d76e0798144f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "c74844eb3c80834b"
   },
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=userdata.get('HF_TOKEN'))\n",
    "\n",
    "model_name = \"speakleash/Bielik-4.5B-v3.0-Instruct\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ],
   "id": "c74844eb3c80834b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "1ad0a6c0f3058dc0"
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Przepis na jajecznicę w dwóch zdaniach\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(input_ids, max_new_tokens=1000)\n",
    "response = tokenizer.batch_decode(outputs)[0]\n",
    "print(response)"
   ],
   "id": "1ad0a6c0f3058dc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from google.colab import drive\n",
    "from benchmark_framework.models.bielik import BielikModel\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "exam_path = '/content/drive/MyDrive/example_exams/2024.jsonl'\n",
    "\n",
    "bielik = BielikModel(\"speakleash/Bielik-11B-v2.2-Instruct\")\n",
    "\n",
    "# with open(exam_path, 'r', encoding='utf-8') as f:\n",
    "#     for line in f:\n",
    "#         try:\n",
    "#             obj = json.loads(line)\n",
    "#             print(obj)\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(line.rstrip())\n"
   ],
   "metadata": {
    "id": "8ZeEvyivBkW5"
   },
   "id": "8ZeEvyivBkW5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
