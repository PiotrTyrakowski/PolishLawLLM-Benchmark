{
  "cells": [
    {
      "metadata": {
        "id": "a7137b7b16ff965e"
      },
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PiotrTyrakowski/PolishLawLLM-Benchmark/blob/KwiatkowskiML/bielik-notebook/notebooks/bielik.ipynb)\n"
      ],
      "id": "a7137b7b16ff965e"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b KwiatkowskiML/bielik-notebook https://github.com/PiotrTyrakowski/PolishLawLLM-Benchmark.git"
      ],
      "metadata": {
        "id": "UwRNKw_wLppv"
      },
      "id": "UwRNKw_wLppv",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "520fa617a1609128"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 6,
      "source": [
        "!pip install -q transformers torch accelerate sentencepiece"
      ],
      "id": "520fa617a1609128"
    },
    {
      "metadata": {
        "id": "b8d3d76e0798144f"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "id": "b8d3d76e0798144f"
    },
    {
      "metadata": {
        "id": "c74844eb3c80834b"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=userdata.get('HF_TOKEN'))\n",
        "\n",
        "model_name = \"speakleash/Bielik-4.5B-v3.0-Instruct\"\n",
        "\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(\"Loading model...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "id": "c74844eb3c80834b"
    },
    {
      "metadata": {
        "id": "1ad0a6c0f3058dc0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Przepis na jajecznicę w dwóch zdaniach\"\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(input_ids, max_new_tokens=1000)\n",
        "response = tokenizer.batch_decode(outputs)[0]\n",
        "print(response)"
      ],
      "id": "1ad0a6c0f3058dc0"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "exam_path = '/content/drive/MyDrive/example_exams/2024.jsonl'\n",
        "SYSTEM_PROMPT = (\n",
        "    \"Jesteś ekspertem w prawie polskim biorącym udział w egzaminie zawodowym. \"\n",
        "    \"Twoim zadaniem jest rozwiązanie pytań testowych z zakresu polskiego prawa. \"\n",
        "    \"Każde pytanie ma dokładnie trzy możliwe odpowiedzi: A, B, C. \"\n",
        "    \"Tylko jedna odpowiedź jest prawidłowa.\\n\\n\"\n",
        "    \"INSTRUKCJE:\\n\"\n",
        "    \"1. Przeanalizuj dokładnie treść pytania i kontekst prawny\\n\"\n",
        "    \"2. Rozważ każdą opcję (A, B, C) krok po kroku:\\n\"\n",
        "    \"   - Oceń zgodność z obowiązującymi przepisami polskiego prawa\\n\"\n",
        "    \"   - Sprawdź precyzyjność sformułowania\\n\"\n",
        "    \"   - Uwzględnij aktualny stan prawny i orzecznictwo\\n\"\n",
        "    \"3. Wyjaśnij swoje rozumowanie dla każdej opcji\\n\"\n",
        "    \"4. Wybierz odpowiedź najbardziej zgodną z polskim prawem\\n\"\n",
        "    \"5. Zakończ swoją odpowiedź w formacie: ANSWER: X (gdzie X to A, B lub C)\\n\\n\"\n",
        "    \"WAŻNE: Zawsze zakończ dokładnie tekstem 'ANSWER: ' oraz jedną literą (A, B lub C).\"\n",
        ")\n",
        "\n",
        "with open(exam_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "            print(obj)\n",
        "        except json.JSONDecodeError:\n",
        "            print(line.rstrip())\n"
      ],
      "metadata": {
        "id": "8ZeEvyivBkW5"
      },
      "id": "8ZeEvyivBkW5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}