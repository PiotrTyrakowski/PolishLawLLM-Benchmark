# Polish Law LLM Benchmark

A benchmark framework for evaluating Large Language Models on Polish legal tasks, including bar exam questions and court judgment analysis.

## Project Structure

```
PolishLawLLM-Benchmark/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ benchmark_framework/    # LLM benchmarking framework
â”‚   â”œâ”€â”€ parsers/                # PDF parsing for exam data extraction
â”‚   â”œâ”€â”€ uploaders/              # Upload results to Firebase
â”‚   â””â”€â”€ common/                 # Shared utilities and domain models
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/                   # Source PDF files (exams, legal codes)
â”‚   â”œâ”€â”€ corpuses/               # Extracted legal code articles (JSON)
â”‚   â”œâ”€â”€ tasks/                  # Benchmark tasks (JSONL)
â”‚   â””â”€â”€ results/                # Benchmark results
â””â”€â”€ frontend/                   # Results visualization dashboard
```

## Quick Start

### Installation

```bash
git clone <repository-url>
cd PolishLawLLM-Benchmark
pip install -r requirements.txt
```

### Environment Variables

```bash
export GOOGLE_API_KEY="..."      # For Gemini models
export OPENAI_API_KEY="..."      # For GPT models
export ANTHROPIC_API_KEY="..."   # For Claude models
export NVIDIA_API_KEY="..."      # For NVIDIA-hosted models
```

### Run a Benchmark

```bash
python -m src.benchmark_framework.cli gemini-2.0-flash exams
```

---

## Modules

### Benchmark Framework

Run LLM evaluations, calculate metrics, and aggregate statistics.

```bash
# Run benchmark
python -m src.benchmark_framework.cli <model-name> <task-type>

# Calculate metrics on results
python -m src.benchmark_framework.calculate_metrics <input-dir> <output-dir>

# Get aggregate statistics
python -m src.benchmark_framework.calculate_stats <file-path>
```

**Supported models:** Gemini, GPT, Claude, NVIDIA (Bielik, DeepSeek, LLaMA, PLLuM)

ðŸ“– **[Detailed documentation â†’](src/benchmark_framework/README.md)**

---

### PDF Parsers

Extract exam questions and legal code articles from PDF files.

```bash
# Generate legal code corpuses
python -m src.parsers.corpuses.setup_corpuses <pdf-dir> <output-dir> <year>

# Parse exam PDFs
python -m src.parsers.cli <pdfs-dir> <corpuses-dir> <output-dir>
```

ðŸ“– **[Detailed documentation â†’](src/parsers/README.md)**

---

### Uploaders

Upload benchmark results to Firebase for visualization in the frontend dashboard.

```bash
python -m src.uploaders.cli <results-dir>
```

ðŸ“– **[Detailed documentation â†’](src/uploaders/Readme.md)**

---

### Frontend

Next.js web dashboard for visualizing benchmark results stored in Firebase.

```bash
cd frontend
bun install
bun run dev
```

ðŸ“– **[Detailed documentation â†’](frontend/README.md)**

---

## Task Types

| Task | Description |
|------|-------------|
| `exams` | Polish legal bar exam questions (adwokacki, radcowy, komorniczy, notarialny) |
| `judgments` | Court judgment analysis tasks |

---

## Development

```bash
# Run tests
python -m pytest src/

# Code formatting
black src/
```
